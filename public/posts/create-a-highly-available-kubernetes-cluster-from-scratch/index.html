<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Liste - https://workingtitle.pro">
    <title>Create a Highly Available Kubernetes Cluster From Scratch | $ root@workingtitle.pro</title>
    <meta name="description" content="A minimal hugo theme focus on content">
    <meta property="og:title" content="Create a Highly Available Kubernetes Cluster From Scratch" />
<meta property="og:description" content="In this guide we’re looking to create a highly available Kubernetes cluster with multiple control plane nodes, loadbalancers and worker nodes.
The architecture of this Kubernetes cluster ensures a good level of availability and reliability for use in a production environment, but it is by no means fail-safe.
I’ve followed the recommendations from Kubernetes documentations which you can find here. All I’ve done is to present them in a curated manner." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://workingtitle.pro/posts/create-a-highly-available-kubernetes-cluster-from-scratch/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-06-20T00:00:00+00:00" />

    <meta itemprop="name" content="Create a Highly Available Kubernetes Cluster From Scratch">
<meta itemprop="description" content="In this guide we’re looking to create a highly available Kubernetes cluster with multiple control plane nodes, loadbalancers and worker nodes.
The architecture of this Kubernetes cluster ensures a good level of availability and reliability for use in a production environment, but it is by no means fail-safe.
I’ve followed the recommendations from Kubernetes documentations which you can find here. All I’ve done is to present them in a curated manner."><meta itemprop="datePublished" content="2022-06-20T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-06-20T00:00:00+00:00" />
<meta itemprop="wordCount" content="1131">
<meta itemprop="keywords" content="" />
    
    <link rel="canonical" href="https://workingtitle.pro/posts/create-a-highly-available-kubernetes-cluster-from-scratch/">
    <link rel="icon" href="https://workingtitle.pro/assets/favicon.ico">
    <link rel="dns-prefetch" href="https://www.google-analytics.com">
    <link href="https://www.google-analytics.com" rel="preconnect" crossorigin>
    <link rel="alternate" type="application/atom+xml" title="$ root@workingtitle.pro" href="https://workingtitle.pro/atom.xml" />
    <link rel="alternate" type="application/json" title="$ root@workingtitle.pro" href="https://workingtitle.pro/feed.json" />
    <link rel="shortcut icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII=">
    
    <style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:#f5f5f5;color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5,strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a,a:visited{color:inherit}a:hover,a.heading-link{text-decoration:none}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:square}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:70ch;margin:0 auto}header{line-height:2;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:120px;width:120px;position:relative;margin:-10px 0 0 15px;float:right;border-radius:50%}</style>
  
    
  
  
  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "BlogPosting",
      "articleSection": "posts",
      "name": "Create a Highly Available Kubernetes Cluster From Scratch",
      "headline": "Create a Highly Available Kubernetes Cluster From Scratch",
      "alternativeHeadline": "",
      "description": "In this guide we’re looking to create a highly available Kubernetes cluster with multiple control plane nodes, loadbalancers and worker nodes.\nThe architecture of this Kubernetes cluster ensures a good level of availability and reliability for use in a production environment, but it is by no means fail-safe.\nI’ve followed the recommendations from Kubernetes documentations which you can find here. All I’ve done is to present them in a curated manner.",
      "inLanguage": "en-us",
      "isFamilyFriendly": "true",
      "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https:\/\/workingtitle.pro\/posts\/create-a-highly-available-kubernetes-cluster-from-scratch\/"
      },
      "author" : {
          "@type": "Person",
          "name": ""
      },
      "creator" : {
          "@type": "Person",
          "name": ""
      },
      "accountablePerson" : {
          "@type": "Person",
          "name": ""
      },
      "copyrightHolder" : "$ root@workingtitle.pro",
      "copyrightYear" : "2022",
      "dateCreated": "2022-06-20T00:00:00.00Z",
      "datePublished": "2022-06-20T00:00:00.00Z",
      "dateModified": "2022-06-20T00:00:00.00Z",
      "publisher":{
          "@type":"Organization",
          "name": "$ root@workingtitle.pro",
          "url": "https://workingtitle.pro",
          "logo": {
              "@type": "ImageObject",
              "url": "https:\/\/workingtitle.pro\/assets\/favicon.ico",
              "width":"32",
              "height":"32"
          }
      },
      "image": "https://workingtitle.pro/assets/favicon.ico",
      "url" : "https:\/\/workingtitle.pro\/posts\/create-a-highly-available-kubernetes-cluster-from-scratch\/",
      "wordCount" : "1131",
      "genre" : [ ],
      "keywords" : [ ]
  }
  </script>
  
  
  </head>
<body>
  <a class="skip-link" href="#main">Skip to main</a>
  <main id="main">
  <div class="content">
    <header>
<p style="padding: 0;margin: 0;">
  <a href="/">
    <b>$ root@workingtitle.pro</b>
    <span class="text-stone-500 animate-blink">▮</span>
  </a>
</p>
<ul style="padding: 0;margin: 0;">
  
  
  <li class="">
    <a href="/posts/"><span>Post</span></a>
    
  <li class="">
    <a href="/about/"><span>About</span></a>
    
  </li>
</ul>
</header>
<hr class="hr-list" style="padding: 0;margin: 0;">
    <section>
      <h2 class="post">Create a Highly Available Kubernetes Cluster From Scratch</h2>
      <p>In this guide we’re looking to create a highly available Kubernetes cluster with multiple control plane nodes, loadbalancers and worker nodes.</p>
<p>The architecture of this Kubernetes cluster ensures a good level of availability and reliability for use in a production environment, but it is by no means fail-safe.</p>
<p>I’ve followed the recommendations from Kubernetes documentations which you can find <a href="https://kubernetes.io/docs/home/">here</a>. All I’ve done is to present them in a curated manner.</p>
<h2 id="what-youll-need">What you’ll need</h2>
<ul>
<li>3 Virtual machines for master nodes  running Debian or CentOS  with at least 2 GB of RAM and 2 CPU cores</li>
<li>2 worker nodes running Debian or CentOs. It can be either VM’s or bare-metal servers. Use full bare metal servers if you have heavy workloads</li>
<li>At least 2 virtual machines running Debian or CentOs for load balancing</li>
</ul>
<br>
<h2 id="architecture">Architecture</h2>
<p><img
  src="https://workingtitle.pro/images/kuber-arch.png"
  alt="kuber-arch"
  loading="lazy"
  decoding="async"
  class="full-width"
/>

</p>
<ul>
<li>3 separate master nodes (control planes) for redundancy</li>
<li>the master nodes are connected via loadbalancer</li>
<li>we’ll have at least 2 load balancing instance where they negotiate a virtual IP between the instances</li>
<li>worker nodes connect to the loadbalancer and the loadbalancer distributes request between control plane nodes</li>
</ul>
<br>
<h2 id="setting-up-the-load-balancers">Setting up the Load balancers</h2>
<p>We’ll be using HA proxy and Keepalived for the load balancing solution. I’ve followed <a href="https://github.com/kubernetes/kubeadm/blob/main/docs/ha-considerations.md#options-for-software-load-balancing">this guide</a> for reference.</p>
<ul>
<li>Install HAProxy and Keepalived on both load balancing server</li>
</ul>
<pre tabindex="0"><code> apt install haproxy
</code></pre><pre tabindex="0"><code>apt install keepalived
</code></pre><ul>
<li>Edit /etc/keepalived/keepalived.conf and make the configurations</li>
</ul>
<pre tabindex="0"><code>! /etc/keepalived/keepalived.conf
! Configuration File for keepalived
global_defs {
    router_id LVS_DEVEL
}

vrrp_script check_apiserver {
  script &#34;/etc/keepalived/check_apiserver.sh&#34;
  interval 3
  weight -2
  fall 10
  rise 2
}

vrrp_instance VI_1 {
    state ${STATE}
    interface ${INTERFACE}
    virtual_router_id ${ROUTER_ID}
    priority ${PRIORITY}
    authentication {
        auth_type PASS
        auth_pass ${AUTH_PASS}
    }

    virtual_ipaddress {
        ${APISERVER_VIP}
    }

    track_script {
        check_apiserver
    }

}
</code></pre><ul>
<li>Add the script for health checking <code>/etc/keepalived/check_apiserver.sh</code></li>
</ul>
<pre tabindex="0"><code>#!/bin/sh
errorExit() {
    echo &#34;*** $*&#34; 1&gt;&amp;2
    exit 1
}

curl --silent --max-time 2 --insecure https://localhost:${APISERVER_DEST_PORT}/ -o /dev/null || errorExit &#34;Error GET https://localhost:${APISERVER_DEST_PORT}/&#34;

if ip addr | grep -q ${APISERVER_VIP}; then

    curl --silent --max-time 2 --insecure https://${APISERVER_VIP}:${APISERVER_DEST_PORT}/ -o /dev/null || errorExit &#34;Error GET https://${APISERVER_VIP}:${APISERVER_DEST_PORT}/&#34;

fi
</code></pre><ul>
<li>Edit <code>/etc/haproxy/haproxy.cfg</code> and make the configurations based on the guide</li>
</ul>
<pre tabindex="0"><code># /etc/haproxy/haproxy.cfg
#---------------------------------------------------------------------
# Global settings
#---------------------------------------------------------------------
global
    log /dev/log local0
    log /dev/log local1 notice
    daemon
#---------------------------------------------------------------------
# common defaults that all the &#39;listen&#39; and &#39;backend&#39; sections will
# use if not designated in their block
#---------------------------------------------------------------------
defaults
    mode                    http
    log                     global
    option                  httplog
    option                  dontlognull
    option http-server-close
    option forwardfor       except 127.0.0.0/8
    option                  redispatch
    retries                 1
    timeout http-request    10s
    timeout queue           20s
    timeout connect         5s
    timeout client          20s
    timeout server          20s
    timeout http-keep-alive 10s
    timeout check           10s
#---------------------------------------------------------------------
# apiserver frontend which proxys to the control plane nodes
#---------------------------------------------------------------------
frontend apiserver
    bind *:${APISERVER_DEST_PORT}
    mode tcp
    option tcplog
    default_backend apiserver
#---------------------------------------------------------------------
# round robin balancing for apiserver
#---------------------------------------------------------------------
backend apiserver
    option httpchk GET /healthz
    http-check expect status 200
    mode tcp
    option ssl-hello-chk
    balance     roundrobin
        server ${HOST1_ID} ${HOST1_ADDRESS}:${APISERVER_SRC_PORT} check
</code></pre><ul>
<li>The configuration on both servers can be identical except two parts in the keepalived configuration:</li>
</ul>
<pre tabindex="0"><code>state MASTER
</code></pre><pre tabindex="0"><code>state BACKUP
</code></pre><p>The <code>MASTER</code> state should be on the main load balancer node and the <code>BACKUP</code>  state should be used on all others. You can have many <code>BACKUP</code>  nodes with the same state.</p>
<pre tabindex="0"><code>priority ${PRIORITY}
</code></pre><p>Should be <b>LOWER</b> on the <code>MASTER</code> server. For example you can configure priority 100 on the <code>MASTER</code> server, priority 101 on the first <code>BACKUP</code> server, priority 102 on the second <code>BACKUP</code> server and so on.</p>
<pre tabindex="0"><code>option httpchk GET /healthz
</code></pre><p>This option should probably be changed to /livez. Check your kube-apiserver configuration file and match it to this value.</p>
<ul>
<li>Once the configuration on both servers is done restart the services</li>
</ul>
<pre tabindex="0"><code>service haproxy restart
</code></pre><pre tabindex="0"><code>service keepalived restart
</code></pre><br>
<h2 id="setting-up-master-nodes">Setting up master nodes</h2>
<br>
<h3 id="first-master-node-main-control-plane">First master node (main control plane)</h3>
<p><b>IMPORTANT NOTE:</b></p>
<p>On Debian machines, you need to edit <code>/etc/default/grub</code> and set <code>systemd.unified_cgroup_hierarchy=0</code> as the value for <code>GRUB_CMDLINE_LINUX_DEFAULT</code> as so:</p>
<pre tabindex="0"><code>GRUB_CMDLINE_LINUX_DEFAULT=&#34;systemd.unified_cgroup_hierarchy=0&#34;
</code></pre><p>Then update grub:</p>
<pre tabindex="0"><code>update-grub
</code></pre><p>and reboot the server.</p>
<ul>
<li>
<p><code>yum update</code> OR <code>apt update</code> &amp;&amp; apt upgrade</p>
</li>
<li>
<p>Disable SElinux (for CentOS)</p>
</li>
</ul>
<pre tabindex="0"><code>nano  /etc/selinux/config
.
.
.
SELINUX=disabled
</code></pre><ul>
<li>Letting iptables see bridged traﬃc</li>
</ul>
<pre tabindex="0"><code>cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
</code></pre><pre tabindex="0"><code>sysctl --system
</code></pre><ul>
<li>Set all hostnames in <code>/etc/hosts</code> if you’re not using a DNS serve</li>
<li>Turn off swap</li>
</ul>
<pre tabindex="0"><code>swapoff -a
</code></pre><ul>
<li>Open /etc/fstab and comment out the section related to swap</li>
<li><a href="https://docs.docker.com/engine/install/">Install Docker</a></li>
<li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">Install kubeadm</a></li>
<li>Open ports with firewalld</li>
</ul>
<pre tabindex="0"><code>sudo firewall-cmd --zone=public --permanent --add-port=6443/tcp
sudo firewall-cmd --zone=public --permanent --add-port=2379-2381/tcp
sudo firewall-cmd --zone=public --permanent --add-port=10250/tcp
sudo firewall-cmd --zone=public --permanent --add-port=10257/tcp
sudo firewall-cmd --reload
</code></pre><ul>
<li>Configure native cgroups driver</li>
</ul>
<pre tabindex="0"><code>cat &gt; /etc/docker/daemon.json &lt;&lt;EOF{
  &#34;exec-opts&#34;: [&#34;native.cgroupdriver=systemd&#34;],
  &#34;log-driver&#34;: &#34;json-file&#34;,
  &#34;log-opts&#34;: {
    &#34;max-size&#34;: &#34;100m&#34;
  },
  &#34;storage-driver&#34;: &#34;overlay2&#34;,
  &#34;storage-opts&#34;: [
    &#34;overlay2.override_kernel_check=true&#34;
  ]
}
EOF
</code></pre><ul>
<li>Then apply the changes</li>
</ul>
<pre tabindex="0"><code>systemctl daemon-reload
</code></pre><pre tabindex="0"><code>systemctl restart docker
</code></pre><ul>
<li>Pull kubeadm images</li>
</ul>
<pre tabindex="0"><code>kubeadm config images pull --kubernetes-version v1.24.0
</code></pre><p>You can specify the desired version with <code>&ndash;kubernetes-version</code>. It’s recommended for all nodes to have the same version so it’s better to manually pull the same version on each master node as to avoid confusion.</p>
<ul>
<li>After successfully pulling the images, initialize the master node via this command:</li>
</ul>
<pre tabindex="0"><code>kubeadm init  --apiserver-advertise-address=CLUSTER-ENDPOINT --control-plane-endpoint=cluster-endpoint --pod-network-cidr=10.244.0.0/16 --upload-certs --kubernetes-version v1.24.0
</code></pre><p><code>CLUSTER-ENDPOINT</code> should point to the virtual IP of the loadbalancer. You can define it in <code>/etc/hosts</code> if you’re not using a DNS server.</p>
<ul>
<li>Apply flannel for cluster networking</li>
</ul>
<pre tabindex="0"><code>kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
</code></pre><ul>
<li>Check the status of pods via:</li>
</ul>
<pre tabindex="0"><code>kubectl  get pods -A
</code></pre><p>Everything should be running normally.</p>
<ul>
<li>Save the output from the kubeadm init command so it can be used for starting other master and worker nodes</li>
</ul>
<br>
<h2 id="second-and-third-master-nodes">Second and Third Master nodes</h2>
<ul>
<li>Follow all of the steps mentioned in the previous section and pull the kubeadm images with:</li>
</ul>
<pre tabindex="0"><code>kubeadm config images pull --kubernetes-version v1.24.0
</code></pre><ul>
<li>Join the second and third master nodes to the cluster via the output from the first master node.</li>
</ul>
<pre tabindex="0"><code>Kubectl join … 
</code></pre><br>
<h2 id="adding-worker-nodes-to-the-cluster">Adding worker nodes to the cluster</h2>
<ul>
<li>Login to your worker node(s)</li>
<li>Follow the same steps from the master node installation and pull the kubeadm images with:</li>
</ul>
<pre tabindex="0"><code>kubeadm config images pull --kubernetes-version v1.24.0
</code></pre><ul>
<li>Open the following ports with iptables or other firewall</li>
</ul>
<pre tabindex="0"><code>iptables -A INPUT -p tcp --dport 10250 -j ACCEPT
iptables -A INPUT -p tcp --dport 30000:35000 -j ACCEPT
iptables -A INPUT -p tcp --dport 10248 -j ACCEPT
iptables-save &gt; /etc/iptables/rules.v4
</code></pre><ul>
<li>
<p>Make sure DNS names are configured in <code>/etc/hosts</code> and the nameservers are set in <code>/etc/resolv.conf</code></p>
</li>
<li>
<p>Use kubeadm join command with the token acquired from the first master node to join the server into the cluster</p>
</li>
<li>
<p>Finally, log into one of your master node (control plane) and run the following command to see all the joined nodes:</p>
</li>
</ul>
<pre tabindex="0"><code>kubectl get nodes -A
</code></pre><p>You should see an output of all your nodes. (master + worker nodes)</p>
<p>Hopefully this article helped you in learning how to create a highly available Kubernetes cluster.</p>
<h2 id="resources">Resources</h2>
<ul>
<li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/">Create a highly available Kubernetes cluster</a></li>
<li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">Creating clusters with kubeadm</a></li>
<li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">Installing kubeadm</a></li>
<li><a href="https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/">kubelet configuration</a></li>
<li><a href="https://stackoverflow.com/questions/52645473/coredns-fails-to-run-in-kubernetes-cluster">Issues with coreDNS</a></li>
<li><a href="https://serverfault.com/questions/1055263/kube-apiserver-exits-while-control-plane-joining-the-ha-cluster">edit KUBELET_NETWORK_ARGS</a></li>
<li><a href="https://linuxize.com/post/how-to-disable-selinux-on-centos-7/">Disable selinux</a></li>
<li><a href="https://serverfault.com/questions/288648/disable-the-public-key-check-for-rpm-installation">Disable GPG checking</a></li>
<li><a href="https://stackoverflow.com/questions/43794169/docker-change-cgroup-driver-to-systemd">Define cgroups driver systemd</a></li>
<li><a href="https://discuss.kubernetes.io/t/why-does-etcd-fail-with-debian-bullseye-kernel/19696">kube-schedular fails on debain</a></li>
</ul>

      
      <div class="post-date">
        <span class="g time">June 20, 2022 </span> &#8729;
         
      </div>
      
    </section>
    
    <div id="comments">
      <script src="https://utteranc.es/client.js"
    repo=ali-foroughi/workingtitle.pro
    issue-term="pathname"
    theme=github-light
    crossorigin="anonymous"
    async>
</script>

    </div>
    
  </div>
</main>
</body>
</html>
