<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Liste - https://workingtitle.pro">
    <title>Graylog on Docker — Part 3: Graylog!  | $ root@workingtitle.pro</title>
    <meta name="description" content="A minimal hugo theme focus on content">
    <meta property="og:title" content="Graylog on Docker — Part 3: Graylog! " />
<meta property="og:description" content="Now that we have a working Elasticsearch cluster and a MongoDB replica set, we can move to the final piece of the puzzle — the Graylog cluster!
We will deploy 3 Graylog containers, one of which be will denoted as &ldquo;master&rdquo;, using the is_master = true parameter in the configuration file. The other two containers will be worker nodes and will have identical configurations.
Here&rsquo;s our master configuration file:
is_master = true node_id_file = /usr/share/graylog/node-id password_secret = YmojUZtpNEXM9c9ztbrCrfKEcYHhHj3RmRADpR7kYwHE2Tybg5fFWYAgdAsPvivJC2qkjCJonDqmnRiFeRsQM root_password_sha2 = 4faeec746f8ea72b8d89c91c8122acb828432f8c145bff35c4f3466477d0ec6e root_timezone = Asia/Tehran http_bind_address = 0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://workingtitle.pro/posts/graylog-on-docker-part-3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-30T17:31:00+03:30" />
<meta property="article:modified_time" content="2023-07-30T17:31:00+03:30" />

    <meta itemprop="name" content="Graylog on Docker — Part 3: Graylog! ">
<meta itemprop="description" content="Now that we have a working Elasticsearch cluster and a MongoDB replica set, we can move to the final piece of the puzzle — the Graylog cluster!
We will deploy 3 Graylog containers, one of which be will denoted as &ldquo;master&rdquo;, using the is_master = true parameter in the configuration file. The other two containers will be worker nodes and will have identical configurations.
Here&rsquo;s our master configuration file:
is_master = true node_id_file = /usr/share/graylog/node-id password_secret = YmojUZtpNEXM9c9ztbrCrfKEcYHhHj3RmRADpR7kYwHE2Tybg5fFWYAgdAsPvivJC2qkjCJonDqmnRiFeRsQM root_password_sha2 = 4faeec746f8ea72b8d89c91c8122acb828432f8c145bff35c4f3466477d0ec6e root_timezone = Asia/Tehran http_bind_address = 0."><meta itemprop="datePublished" content="2023-07-30T17:31:00+03:30" />
<meta itemprop="dateModified" content="2023-07-30T17:31:00+03:30" />
<meta itemprop="wordCount" content="647">
<meta itemprop="keywords" content="" />
    
    <link rel="canonical" href="https://workingtitle.pro/posts/graylog-on-docker-part-3/">
    <link rel="icon" href="https://workingtitle.pro/assets/favicon.ico">
    <link rel="dns-prefetch" href="https://www.google-analytics.com">
    <link href="https://www.google-analytics.com" rel="preconnect" crossorigin>
    <link rel="alternate" type="application/atom+xml" title="$ root@workingtitle.pro" href="https://workingtitle.pro/atom.xml" />
    <link rel="alternate" type="application/json" title="$ root@workingtitle.pro" href="https://workingtitle.pro/feed.json" />
    <link rel="shortcut icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII=">
    
    <style>*,:after,:before{box-sizing:border-box;padding:0}body{font:1rem/1.5 '-apple-system',BlinkMacSystemFont,avenir next,avenir,helvetica,helvetica neue,ubuntu,roboto,noto,segoe ui,arial,sans-serif;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;padding:2rem;background:#f5f5f5;color:#000}.skip-link{position:absolute;top:-40px;left:0;background:#eee;z-index:100}.skip-link:focus{top:0}h1,h2,h3,h4,h5,strong,b{font-size:inherit;font-weight:600}header{line-height:2;padding-bottom:1.5rem}.link{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.time{font-variant-numeric:tabular-nums;white-space:nowrap}blockquote{border-left:5px solid #eee;padding-left:1rem;margin:0}a,a:visited{color:inherit}a:hover,a.heading-link{text-decoration:none}pre{padding:.5rem;overflow:auto;overflow-x:scroll;overflow-wrap:normal}code,pre{font-family:San Francisco Mono,Monaco,consolas,lucida console,dejavu sans mono,bitstream vera sans mono,monospace;font-size:normal;font-size:small;background:#eee}code{margin:.1rem;border:none}ul{list-style-type:square}ul,ol{padding-left:1.2rem}.list{line-height:2;list-style-type:none;padding-left:0}.list li{padding-bottom:.1rem}.meta{color:#777}.content{max-width:70ch;margin:0 auto}header{line-height:2;display:flex;justify-content:space-between;padding-bottom:1rem}header a{text-decoration:none}header ul{list-style-type:none;padding:0}header li,header a{display:inline}h2.post{padding-top:.5rem}header ul a:first-child{padding-left:1rem}.nav{height:1px;background:#000;content:'';max-width:10%}.list li{display:flex;align-items:baseline}.list li time{flex:initial}.hr-list{margin-top:0;margin-bottom:0;margin-right:.5rem;margin-left:.5rem;height:1px;border:0;flex:1 0 1rem}.m,hr{border:0;margin:3rem 0}img{max-width:100%;height:auto}.post-date{margin:5% 0}.index-date{color:#9a9a9a}.animate-blink{animation:opacity 1s infinite;opacity:1}@keyframes opacity{0%{opacity:1}50%{opacity:.5}100%{opacity:0}}.tags{display:flex;justify-content:space-between}.tags ul{padding:0;margin:0}.tags li{display:inline}.avatar{height:120px;width:120px;position:relative;margin:-10px 0 0 15px;float:right;border-radius:50%}</style>
  
    
  
  
  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "BlogPosting",
      "articleSection": "posts",
      "name": "Graylog on Docker — Part 3: Graylog! ",
      "headline": "Graylog on Docker — Part 3: Graylog! ",
      "alternativeHeadline": "",
      "description": "Now that we have a working Elasticsearch cluster and a MongoDB replica set, we can move to the final piece of the puzzle — the Graylog cluster!\nWe will deploy 3 Graylog containers, one of which be will denoted as \u0026ldquo;master\u0026rdquo;, using the is_master = true parameter in the configuration file. The other two containers will be worker nodes and will have identical configurations.\nHere\u0026rsquo;s our master configuration file:\nis_master = true node_id_file = \/usr\/share\/graylog\/node-id password_secret = YmojUZtpNEXM9c9ztbrCrfKEcYHhHj3RmRADpR7kYwHE2Tybg5fFWYAgdAsPvivJC2qkjCJonDqmnRiFeRsQM root_password_sha2 = 4faeec746f8ea72b8d89c91c8122acb828432f8c145bff35c4f3466477d0ec6e root_timezone = Asia\/Tehran http_bind_address = 0.",
      "inLanguage": "en-us",
      "isFamilyFriendly": "true",
      "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https:\/\/workingtitle.pro\/posts\/graylog-on-docker-part-3\/"
      },
      "author" : {
          "@type": "Person",
          "name": ""
      },
      "creator" : {
          "@type": "Person",
          "name": ""
      },
      "accountablePerson" : {
          "@type": "Person",
          "name": ""
      },
      "copyrightHolder" : "$ root@workingtitle.pro",
      "copyrightYear" : "2023",
      "dateCreated": "2023-07-30T17:31:00.00Z",
      "datePublished": "2023-07-30T17:31:00.00Z",
      "dateModified": "2023-07-30T17:31:00.00Z",
      "publisher":{
          "@type":"Organization",
          "name": "$ root@workingtitle.pro",
          "url": "https://workingtitle.pro",
          "logo": {
              "@type": "ImageObject",
              "url": "https:\/\/workingtitle.pro\/assets\/favicon.ico",
              "width":"32",
              "height":"32"
          }
      },
      "image": "https://workingtitle.pro/assets/favicon.ico",
      "url" : "https:\/\/workingtitle.pro\/posts\/graylog-on-docker-part-3\/",
      "wordCount" : "647",
      "genre" : [ ],
      "keywords" : [ ]
  }
  </script>
  
  
  </head>
<body>
  <a class="skip-link" href="#main">Skip to main</a>
  <main id="main">
  <div class="content">
    <header>
<p style="padding: 0;margin: 0;">
  <a href="/">
    <b>$ root@workingtitle.pro</b>
    <span class="text-stone-500 animate-blink">▮</span>
  </a>
</p>
<ul style="padding: 0;margin: 0;">
  
  
  <li class="">
    <a href="/posts/"><span>Post</span></a>
    
  <li class="">
    <a href="/about/"><span>About</span></a>
    
  </li>
</ul>
</header>
<hr class="hr-list" style="padding: 0;margin: 0;">
    <section>
      <h2 class="post">Graylog on Docker — Part 3: Graylog! </h2>
      <p>Now that we have a working <a href="https://workingtitle.pro/posts/graylog-on-docker-part-1/">Elasticsearch cluster</a> and a <a href="https://workingtitle.pro/posts/graylog-on-docker-part-2/">MongoDB replica set</a>, we can move to the final piece of the puzzle — the Graylog cluster!</p>
<p>We will deploy 3 Graylog containers, one of which be will denoted as &ldquo;master&rdquo;, using the <code>is_master = true</code> parameter in the configuration file. The other two containers will be worker nodes and will have identical configurations.</p>
<p>Here&rsquo;s our master configuration file:</p>
<pre tabindex="0"><code>is_master = true
node_id_file = /usr/share/graylog/node-id
password_secret = YmojUZtpNEXM9c9ztbrCrfKEcYHhHj3RmRADpR7kYwHE2Tybg5fFWYAgdAsPvivJC2qkjCJonDqmnRiFeRsQM
root_password_sha2 = 4faeec746f8ea72b8d89c91c8122acb828432f8c145bff35c4f3466477d0ec6e
root_timezone = Asia/Tehran
http_bind_address = 0.0.0.0:9000
elasticsearch_hosts = http://es01.example.net:9201,http://es02.example.net:9202,http://es03.example.net:9203
rotation_strategy = count
elasticsearch_max_docs_per_index = 20000000
elasticsearch_max_number_of_indices = 20
retention_strategy = delete
elasticsearch_shards = 4
elasticsearch_replicas = 3
elasticsearch_index_prefix = graylog
allow_leading_wildcard_searches = false
allow_highlighting = false
elasticsearch_analyzer = standard
output_batch_size = 500
output_flush_interval = 1
output_fault_count_threshold = 5
output_fault_penalty_seconds = 30
processbuffer_processors = 5
outputbuffer_processors = 3
processor_wait_strategy = blocking
ring_size = 65536
inputbuffer_ring_size = 65536
inputbuffer_processors = 2
inputbuffer_wait_strategy = blocking
message_journal_enabled = true
lb_recognition_period_seconds = 3
mongodb_uri = mongodb://mongo-cluster:27017,mongo-cluster2:27018,mongo-cluster3:27019/graylog?replicaSet=dbrs
mongodb_max_connections = 1000
mongodb_threads_allowed_to_block_multiplier = 5
proxied_requests_thread_pool_size = 32
</code></pre><p>And this will be our slave configuration file, which is identical to master with the difference that <code>is_master</code> is set to <code>false</code>.</p>
<pre tabindex="0"><code>is_master = false
node_id_file = /usr/share/graylog/node-id
password_secret = YmojUZtpNEXM9c9ztbrCrfKEcYHhHj3RmRADpR7kYwHE2Tybg5fFWYAgdAsPvivJC2qkjCJonDqmnRiFeRsQM
root_password_sha2 = 4faeec746f8ea72b8d89c91c8122acb828432f8c145bff35c4f3466477d0ec6e
root_timezone = Asia/Tehran
http_bind_address = 0.0.0.0:9000
elasticsearch_hosts = http://es01.example.net:9201,http://es02.example.net:9202,http://es03.example.net:9203
rotation_strategy = count
elasticsearch_max_docs_per_index = 20000000
elasticsearch_max_number_of_indices = 20
retention_strategy = delete
elasticsearch_shards = 4
elasticsearch_replicas = 3
elasticsearch_index_prefix = graylog
allow_leading_wildcard_searches = false
allow_highlighting = false
elasticsearch_analyzer = standard
output_batch_size = 500
output_flush_interval = 1
output_fault_count_threshold = 5
output_fault_penalty_seconds = 30
processbuffer_processors = 5
outputbuffer_processors = 3
processor_wait_strategy = blocking
ring_size = 65536
inputbuffer_ring_size = 65536
inputbuffer_processors = 2
inputbuffer_wait_strategy = blocking
message_journal_enabled = true
lb_recognition_period_seconds = 3
mongodb_uri = mongodb://mongo-cluster:27017,mongo-cluster2:27018,mongo-cluster3:27019/graylog?replicaSet=dbrs
mongodb_max_connections = 1000
mongodb_threads_allowed_to_block_multiplier = 5
proxied_requests_thread_pool_size = 32
</code></pre><p>Then we have our final docker compose file:</p>
<pre tabindex="0"><code>version: &#34;3.8&#34;

services:
  graylog-1:
    container_name: graylog-1-master
    image: graylog:5.0.6    
    volumes: 
      - ./graylog-config/master/:/usr/share/graylog/data/config/
    networks:
      - my-overlay-2
    ports:
      - 9000:9000 # Graylog web interface and REST API
      - 1514:1514 # Syslog TCP
      - 1514:1514/udp # Syslog UDP
      - 12201:12201 # GELF TCP
      - 12201:12201/udp # GELF UDP
      - 5045:5044 #Logstash port
    extra_hosts:
      - &#34;es01.example.net:172.17.93.170&#34;
      - &#34;es02.example.net:172.17.93.171&#34;
      - &#34;es03.example.net:172.17.93.172&#34;
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.type == master
      replicas: 1
    entrypoint: [ &#34;/docker-entrypoint.sh&#34; ]

  graylog-2:
    container_name: graylog-2
    image: graylog:5.0.6
    volumes:
      - /opt/graylog-config/slave/:/usr/share/graylog/data/config/
    networks:
      - my-overlay-2
    ports:
      - 9001:9000 # Graylog web interface and REST API
      - 1515:1514 # Syslog TCP
      - 1515:1514/udp # Syslog UDP
      - 12202:12201 # GELF TCP
      - 12202:12201/udp # GELF UDP
      - 5044:5044 #Logstash port
    extra_hosts: 
      - &#34;es01.example.net:172.17.93.170&#34; 
      - &#34;es02.example.net:172.17.93.171&#34;
      - &#34;es03.example.net:172.17.93.172&#34;
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.type == worker-1
      replicas: 1
    entrypoint: [ &#34;/docker-entrypoint.sh&#34; ]

  graylog-3:
    container_name: graylog-3
    image: graylog:5.0.6
    volumes:
      - /opt/graylog-config/slave/:/usr/share/graylog/data/config/
    networks:
      - my-overlay-2
    ports:
      - 9002:9000 # Graylog web interface and REST API
      - 1516:1514 # Syslog TCP
      - 1516:1514/udp # Syslog UDP
      - 12203:12201 # GELF TCP
      - 12203:12201/udp # GELF UDP
      - 5046:5044 #Logstash port
    extra_hosts: 
      - &#34;es01.example.net:172.17.93.170&#34; 
      - &#34;es02.example.net:172.17.93.171&#34;
      - &#34;es03.example.net:172.17.93.172&#34;
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.labels.type == worker-2    
      replicas: 1
    entrypoint: [ &#34;/docker-entrypoint.sh&#34; ]
networks:
  my-overlay-2:
    external: true
</code></pre><p>Here&rsquo;s the breakdown:</p>
<ul>
<li>we&rsquo;re setting up 3 instances of Graylog, one master and two slaves.</li>
<li>The master node gets its own configuration file via volumes and the slaves get their own.</li>
<li>We use placement constraints to place containers on specific nodes, just as we did for the Elasticsearch cluster and MongoDB cluster. This ensures we have the highest level of availability if one of the nodes in our Docker Swarm goes down.</li>
<li>We use <code>extra_hosts</code> to specify the IP address of the nodes where Graylog can access elasticsearch. The addresses specified such as <code>es01.example.net</code> is configured as the elasticsearch node in the Graylog configuration file mentioned before.</li>
<li>Please note that all of our containers in the cluster (Elastic, Mongo, Graylog) use a single shared overlay network (<code>my-overlay-2</code>) so they can access each other.</li>
</ul>

      
      <div class="post-date">
        <span class="g time">July 30, 2023 </span> &#8729;
         
      </div>
      
    </section>
    
    <div id="comments">
      <script src="https://utteranc.es/client.js"
    repo=ali-foroughi/workingtitle.pro
    issue-term="pathname"
    theme=github-light
    crossorigin="anonymous"
    async>
</script>

    </div>
    
  </div>
</main>
</body>
</html>
